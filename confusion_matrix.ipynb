{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe1e23f1",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90f3799",
   "metadata": {},
   "source": [
    "In a binary classification task, there are four possible outcomes for each prediction:\n",
    "\n",
    "True Positive (TP): the model predicted a positive class (1) and the true label was also positive (1)\n",
    "    \n",
    "True Negative (TN): the model predicted a negative class (0) and the true label was also negative (0)\n",
    "    \n",
    "False Positive (FP): the model predicted a positive class (1) but the true label was actually negative (0)\n",
    "    \n",
    "False Negative (FN): the model predicted a negative class (0) but the true label was actually positive (1)\n",
    "    \n",
    "The ground truth refers to the true labels for each instance in the dataset, which are known in advance and used for evaluation. The predicted labels are the output of the model after it has been trained on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21f7e7",
   "metadata": {},
   "source": [
    "The ground truth refers to the true labels for each instance in the dataset, which are known in advance and used for evaluation. The predicted labels are the output of the model after it has been trained on the data.\n",
    "\n",
    "In the given example, we have:\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "To calculate the number of true positives, true negatives, false positives, and false negatives, we can use the following equations:\n",
    "\n",
    "TP: number of instances where y_true = 1 and y_pred = 1\n",
    "TN: number of instances where y_true = 0 and y_pred = 0\n",
    "FP: number of instances where y_true = 0 and y_pred = 1\n",
    "FN: number of instances where y_true = 1 and y_pred = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37765393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Positive</th>\n",
       "      <th>Actual Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>TP</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>FN</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Actual Positive Actual Negative\n",
       "Predicted Positive              TP              FP\n",
       "Predicted Negative              FN              TN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame({'Actual Positive': ['TP', 'FN'], 'Actual Negative': ['FP', 'TN']}, \n",
    "                                index=['Predicted Positive', 'Predicted Negative'])\n",
    "# Display the dataframe using IPython display function\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf8d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0966a886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                Predicted Positive     Predicted Negative\n",
      "Actual Positive        3                  2\n",
      "Actual Negative        2                  3\n"
     ]
    }
   ],
   "source": [
    "# define ground truth and predicted labels for a binary classification task\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# define variables to keep track of true positives, true negatives,\n",
    "# false positives, and false negatives\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "# iterate over each sample and update the confusion matrix variables\n",
    "for i in range(len(y_true)):\n",
    "    if y_true[i] == 1 and y_pred[i] == 1:\n",
    "        tp += 1\n",
    "    elif y_true[i] == 0 and y_pred[i] == 0:\n",
    "        tn += 1\n",
    "    elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "        fp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "# print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"                Predicted Positive     Predicted Negative\")\n",
    "print(\"Actual Positive        {}                  {}\".format(tp, fn))\n",
    "print(\"Actual Negative        {}                  {}\".format(fp, tn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26701f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Positive</th>\n",
       "      <th>Actual Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Actual Positive  Actual Negative\n",
       "Predicted Positive                3                2\n",
       "Predicted Negative                2                3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
    "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
    "\n",
    "# Calculate true positives, true negatives, false positives, and false negatives\n",
    "tp = sum([1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 1])\n",
    "tn = sum([1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 0])\n",
    "fp = sum([1 for i in range(len(y_true)) if y_true[i] == 0 and y_pred[i] == 1])\n",
    "fn = sum([1 for i in range(len(y_true)) if y_true[i] == 1 and y_pred[i] == 0])\n",
    "\n",
    "# Create a dataframe for the confusion matrix\n",
    "confusion_matrix = pd.DataFrame({'Actual Positive': [tp, fn], 'Actual Negative': [fp, tn]}, \n",
    "                                index=['Predicted Positive', 'Predicted Negative'])\n",
    "\n",
    "# Display the dataframe using IPython display function\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d645083d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c6bea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Positive</th>\n",
       "      <th>Actual Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Positive</th>\n",
       "      <td>TP</td>\n",
       "      <td>FP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative</th>\n",
       "      <td>FN</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Actual Positive Actual Negative\n",
       "Predicted Positive              TP              FP\n",
       "Predicted Negative              FN              TN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the dataframe using IPython display function\n",
    "display(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415c84b",
   "metadata": {},
   "source": [
    "## TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb4ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46103a8ee214334b8dc51f798d6b706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='1, 0, 1, 1, 0, 1, 0, 1, 0, 0', description='Ground Truth:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ac1e9504e44493a7168d6229cd0d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='1, 0, 0, 1, 0, 1, 1, 0, 1, 0', description='Predicted:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41989370f204b0980ff20166bf4008b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Compute', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0873eec728f54b6891c9b4e349191bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "# create widgets for ground truth and predicted labels\n",
    "y_true_widget = widgets.Text(\n",
    "    value='1, 0, 1, 1, 0, 1, 0, 1, 0, 0',\n",
    "    description='Ground Truth:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "y_pred_widget = widgets.Text(\n",
    "    value='1, 0, 0, 1, 0, 1, 1, 0, 1, 0',\n",
    "    description='Predicted:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# define a function to compute the confusion matrix based on the widget values\n",
    "def compute_confusion_matrix(y_true_widget, y_pred_widget):\n",
    "    # extract the values from the widgets and convert them to lists of integers\n",
    "    y_true = [int(x) for x in y_true_widget.value.split(',')]\n",
    "    y_pred = [int(x) for x in y_pred_widget.value.split(',')]\n",
    "\n",
    "    # define variables to keep track of true positives, true negatives,\n",
    "    # false positives, and false negatives\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    # iterate over each sample and update the confusion matrix variables\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1:\n",
    "            tp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 0:\n",
    "            tn += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    # create a widget to display the confusion matrix\n",
    "    cm_widget = widgets.Output()\n",
    "\n",
    "    # print the confusion matrix\n",
    "    with cm_widget:\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(\"                Predicted Positive     Predicted Negative\")\n",
    "        print(\"Actual Positive        {}                  {}\".format(tp, fn))\n",
    "        print(\"Actual Negative        {}                  {}\".format(fp, tn))\n",
    "\n",
    "    # return the confusion matrix widget\n",
    "    return cm_widget\n",
    "\n",
    "# create a button widget to trigger the computation of the confusion matrix\n",
    "compute_button = widgets.Button(description='Compute')\n",
    "\n",
    "# define a function to handle button clicks\n",
    "def on_compute_button_clicked(b):\n",
    "    # compute the confusion matrix based on the current widget values\n",
    "    cm_widget = compute_confusion_matrix(y_true_widget, y_pred_widget)\n",
    "\n",
    "    # clear the output area and display the confusion matrix\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(cm_widget)\n",
    "\n",
    "# register the button click handler function with the button widget\n",
    "compute_button.on_click(on_compute_button_clicked)\n",
    "\n",
    "# create a widget to hold the output\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# display the widgets and output area\n",
    "display(y_true_widget, y_pred_widget, compute_button, output_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf44f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c564a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dc8d05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
