{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9786d82",
   "metadata": {},
   "source": [
    "# Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca16d04",
   "metadata": {},
   "source": [
    "Implementing a simpler Naive Bayes classifier for email spam classification in Python.\n",
    "Naive Bayes is a machine learning algorithm commonly used for classification problems.\n",
    "\n",
    "Essentially, it predicts the probabilities of different classes based on the features of the data.\n",
    "\n",
    "\n",
    "The Naive Bayes classifier is based on the principles of Bayes' theorem. This theorem relates the probability of an event to the conditions under which the event occurs and the available data. The Naive Bayes classifier offers a simple computation method by making assumptions.\n",
    "\n",
    "\n",
    "The \"naive\" name of the Naive Bayes classifier stems from the assumption that each feature is independent of the others. It disregards relationships between features and treats each feature independently. This assumption simplifies the computations and speeds up the classification process.\n",
    "\n",
    "\n",
    "The Naive Bayes classifier calculates the probabilities of features in the dataset. Then, based on the features of a new instance, it predicts the probability values for the class label. The predictions are typically made using the maximum likelihood principle, selecting the class with the highest probability.\n",
    "\n",
    "\n",
    "In this way, the Naive Bayes classifier can be effectively used in classification problems, particularly in areas such as text classification, spam filtering, and sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf0ecc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "832c88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26fa7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,0,1,0],[0,1,1,1],[1,1,0,0],[0,0,1,1]]  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2301df",
   "metadata": {},
   "source": [
    "we can consider the following as a possible fourth feature:\n",
    "\n",
    "Email: Contains the word \"advertisement\", Email length > 100, Sender unknown, Attached file present\n",
    "\n",
    "Email: Does not contain the word \"advertisement\", Email length < 50, Sender known, No attached file\n",
    "\n",
    "Email: Contains the word \"advertisement\", Email length > 100, Sender known, No attached file\n",
    "\n",
    "Email: Does not contain the word \"advertisement\", Email length < 50, Sender unknown, Attached file present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89497546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array([1,0,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66487587",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([[1, 0, 1, 1], [0, 1, 0, 1]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667de693",
   "metadata": {},
   "source": [
    "y_train=np.array([1,0,1,0]) represents the classes of the emails in the training dataset. Here, the labels indicating the class of each email are represented as a NumPy array.\n",
    "\n",
    "Each element of the array corresponds to the classes of the emails in the training dataset, respectively. For example:\n",
    "\n",
    "The first email is labeled as spam (class 1).\n",
    "\n",
    "The second email is labeled as not spam (class 0).\n",
    "\n",
    "The third email is labeled as spam (class 1).\n",
    "\n",
    "The fourth email is labeled as not spam (class 0).\n",
    "\n",
    "In this way, the correct class labels for each email are stored in the y_train array. These labels are used to classify the emails in the training dataset as spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "305c919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "num_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ea98544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a88ac75",
   "metadata": {},
   "source": [
    "classes = np.unique(y_train) and num_classes = len(classes) is used to determine the unique classes present in the training labels (y_train) and calculate the number of unique classes.\n",
    "\n",
    "Here is an explanation of each line:\n",
    "\n",
    "classes = np.unique(y_train): This line uses the np.unique() function from the NumPy library to find the unique elements in the y_train array. It returns an array (classes) containing the unique classes present in y_train.\n",
    "The unique function removes duplicate elements and sorts the array in ascending order.\n",
    "\n",
    "num_classes = len(classes): This line calculates the number of unique classes by using the len() function to get the length of the classes array. The length of an array represents the number of elements in it, so num_classes will store the count of unique classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c338992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_priors = np.zeros(num_classes)\n",
    "for i, cls in enumerate(classes):\n",
    "    class_priors[i] = np.sum(y_train == cls) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f67e51",
   "metadata": {},
   "source": [
    "class_priors = np.zeros(num_classes): This line initializes an array class_priors with zeros, with a length equal to the number of unique classes (num_classes). This array will store the class priors.\n",
    "\n",
    "for i, cls in enumerate(classes):: This line starts a loop that iterates over each unique class in the classes array. It uses the enumerate() function to iterate over both the index (i) and the value (cls) of each element in classes.\n",
    "\n",
    "class_priors[i] = np.sum(y_train == cls) / len(y_train): Inside the loop, this line calculates the class prior probability for the current class (cls). It does so by counting the occurrences of the current class in the y_train array using the expression np.sum(y_train == cls). This counts the number of elements in y_train that are equal to the current class. Then, it divides this count by the total number of training samples (len(y_train)) to obtain the class prior probability. The calculated probability is then assigned to the corresponding index i in the class_priors array.\n",
    "\n",
    "After executing these lines, the class_priors array will contain the calculated class prior probabilities for each unique class in the training data. These probabilities indicate the likelihood of encountering each class in the dataset and can be used as a prior belief in classification tasks.\n",
    "\n",
    "class_priors[i]. Prior belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ffc9b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.shape[1]\n",
    "feature_likelihoods = np.zeros((num_classes, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c789c432",
   "metadata": {},
   "source": [
    "num_features = X_train.shape[1]: This line retrieves the number of features in the training data (X_train). The shape attribute of a NumPy array returns a tuple representing the dimensions of the array. Since X_train is a 2-dimensional array, the shape is given as (num_samples, num_features). By accessing the second element of the shape tuple (X_train.shape[1]), we get the number of features in the dataset, which is stored in the variable num_features.\n",
    "\n",
    "feature_likelihoods = np.zeros((num_classes, num_features)): This line initializes an array feature_likelihoods with zeros. The shape of this array is (num_classes, num_features), where num_classes is the number of unique classes and num_features is the number of features in the training data. This array will store the calculated likelihood probabilities for each feature in each class.\n",
    "\n",
    "After executing these lines, the variable num_features will hold the count of features, and the feature_likelihoods array will be initialized with zeros and ready to store the likelihood probabilities for each feature in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc6e74dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, cls in enumerate(classes):\n",
    "    X_class = X_train[y_train == cls]\n",
    "    feature_likelihoods[i] = np.mean(X_class, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91578c3d",
   "metadata": {},
   "source": [
    "for i, cls in enumerate(classes):: This line initiates a loop that iterates over each unique class in the classes array. The enumerate() function is used to iterate over both the index (i) and the value (cls) of each element in classes.\n",
    "\n",
    "X_class = X_train[y_train == cls]: Inside the loop, this line creates a subset of the training data X_train for the current class (cls). It uses boolean indexing to select rows from X_train where the corresponding label in y_train is equal to the current class. This subset of rows is assigned to the variable X_class.\n",
    "\n",
    "feature_likelihoods[i] = np.mean(X_class, axis=0): This line calculates the feature likelihood probabilities for the current class and assigns them to the corresponding row in the feature_likelihoods array.\n",
    "\n",
    "np.mean(X_class, axis=0) calculates the mean value of each column (feature) in the X_class array. The axis=0 parameter specifies that the mean should be taken along the columns.\n",
    "\n",
    "The resulting mean values represent the likelihood probabilities for each feature in the current class. The calculated probabilities are then assigned to the corresponding row (i) in the feature_likelihoods array, which stores the likelihood probabilities for each feature in each class.\n",
    "\n",
    "The loop repeats for each class, allowing the code to calculate the feature likelihood probabilities for all classes present in the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf43dca",
   "metadata": {},
   "source": [
    "# Explanation of the X_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a774b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "X_class:\n",
      "[[0 1 1 1]\n",
      " [0 0 1 1]]\n",
      "---------\n",
      "Class: 1\n",
      "X_class:\n",
      "[[1 0 1 0]\n",
      " [1 1 0 0]]\n",
      "---------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.array([[1, 0, 1, 0],   # 1. e-posta\n",
    "                   [0, 1, 1, 1],   # 2. e-posta\n",
    "                   [1, 1, 0, 0],   # 3. e-posta\n",
    "                   [0, 0, 1, 1]])  # 4. e-posta\n",
    "y_train = np.array([1, 0, 1, 0])\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "\n",
    "for i, cls in enumerate(classes):\n",
    "    X_class = X_train[y_train == cls]\n",
    "    print(f\"Class: {cls}\")\n",
    "    print(f\"X_class:\\n{X_class}\")\n",
    "    print(\"---------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc083e10",
   "metadata": {},
   "source": [
    "Yukarıdaki örnekte, X_train dizisinde dört e-posta bulunur ve her biri dört özelliği temsil eder. y_train dizisi, her e-postaya karşılık gelen sınıf etiketlerini içerir. Döngüde, enumerate(classes) kullanılarak sınıflar üzerinde dönülür. Her döngü adımında, cls değişkeni geçerli sınıf değerini alır.\n",
    "\n",
    "İlk döngüde, cls değeri 0'dır. y_train == cls ifadesi, y_train dizisini 0 ile karşılaştırır ve bu koşulu sağlayan konumları temsil eden bir boolean maske oluşturur. Bu maske, 0'a karşılık gelen e-postaların bulunduğu satırları seçmek için X_train dizisine uygulanır. Sonuç olarak, X_class değişkeni, 0 sınıfına ait e-postaların özelliklerini içeren bir alt küme olarak atanır.\n",
    "\n",
    "Aynı işlem, ikinci döngü adımında cls değeri 1 olduğunda da tekrarlanır. Bu sefer, y_train dizisindeki 1'lere karşılık gelen e-postaların özelliklerini temsil eden başka bir alt küme olan X_class değişkenine atanır.\n",
    "\n",
    "Bu örnekte, X_class değişkeni, her bir sınıfa ait örneklerin özelliklerini içeren alt kümeleri temsil etmektedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98534ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1848080e",
   "metadata": {},
   "source": [
    "X_train = np.array([[1, 0, 1, 0], # 1. e-posta\n",
    "[0, 1, 1, 1], # 2. e-posta\n",
    "[1, 1, 0, 0], # 3. e-posta\n",
    "[0, 0, 1, 1]]) # 4. e-posta\n",
    "\n",
    "y_train = np.array([1, 0, 1, 0])\n",
    "\n",
    "Sınıflar (yani sınıf etiketleri) ise:\n",
    "\n",
    "classes = np.unique(y_train) # [0, 1]\n",
    "\n",
    "Şimdi, for döngüsü içinde her bir sınıf için ayrı ayrı işlemler yapılıyor.\n",
    "\n",
    "İlk döngü adımında:\n",
    "\n",
    "cls = 0\n",
    "\n",
    "y_train == cls ifadesi, y_train dizisinde 0'ya eşit olan konumları belirleyen bir boolean maske oluşturur. Bu maske [False, True, False, True] şeklindedir.\n",
    "\n",
    "Bu maskeyi X_train dizisine uyguladığımızda, yalnızca True değerlere karşılık gelen satırlar seçilir ve X_class değişkenine atanır. Bu durumda, [False, True, False, True] maskesi, 2. ve 4. satırları seçer ve X_class şu şekilde olur:\n",
    "\n",
    "X_class:\n",
    "[[0 1 1 1]\n",
    "[0 0 1 1]]\n",
    "\n",
    "Bu işlem, 0 sınıfına ait e-postaların özelliklerini içeren X_class alt kümesini elde etmemizi sağlar.\n",
    "\n",
    "İkinci döngü adımında:\n",
    "\n",
    "cls = 1\n",
    "\n",
    "y_train == cls ifadesi, y_train dizisinde 1'e eşit olan konumları belirleyen bir boolean maske oluşturur. Bu maske [True, False, True, False] şeklindedir.\n",
    "\n",
    "Bu maskeyi X_train dizisine uyguladığımızda, yalnızca True değerlere karşılık gelen satırlar seçilir ve X_class değişkenine atanır. Bu durumda, [True, False, True, False] maskesi, 1. ve 3. satırları seçer ve X_class şu şekilde olur:\n",
    "\n",
    "X_class:\n",
    "[[1 0 1 0]\n",
    "[1 1 0 0]]\n",
    "\n",
    "Bu işlem, 1 sınıfına ait e-postaların özelliklerini içeren X_class alt kümesini elde etmemizi sağlar.\n",
    "\n",
    "Sonuç olarak, for döngüsü içindeki işlemler, her bir sınıfa ait e-postaların özelliklerini içeren X_class alt kümelerini oluşturur. Bu alt kümeler, sınıf etiketlerine göre gruplandırılmış özellik veriler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b308a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = X_test.shape[0]\n",
    "predictions = np.zeros(num_samples, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb952d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_samples):\n",
    "    posterior_probs = np.zeros(num_classes)\n",
    "    for j, cls in enumerate(classes):\n",
    "        prior = class_priors[j]\n",
    "        likelihood = np.prod(feature_likelihoods[j] ** X_test[i] * (1 - feature_likelihoods[j]) ** (1 - X_test[i]))\n",
    "        posterior_probs[j] = prior * likelihood\n",
    "\n",
    "    predictions[i] = np.argmax(posterior_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c632e2c0",
   "metadata": {},
   "source": [
    "For each sample in the test data, calculate the posterior probabilities for each class. Multiply the class prior (prior) with the likelihoods of features (likelihood) given that class. \n",
    "Store the class with the highest probability in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c47d804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1 predicted as: ham\n",
      "Sample 2 predicted as: ham\n"
     ]
    }
   ],
   "source": [
    "for i, pred in enumerate(predictions):\n",
    "    print(\"Sample\", i+1, \"predicted as:\", \"spam\" if pred == 1 else \"ham\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c72ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
